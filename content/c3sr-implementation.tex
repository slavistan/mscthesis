\def\ApiHubMlf{http://eigen.tuxfamily.org/index.php?title=Main_Page}

\chapter{Implementation Details}

  In order to assess the viability of the concepts introduced in the previous chapter a prototype software library has
  been implemented. This chapter explains noteworthy design choices and implementation details and takes note where
  alternative options exist.

  \section{Generation of C3SR Matrices From Matrices in CSR Representation} \label{sec:gen-of-c3sr-from-csr}

    The C3SR-format can be understood as a refinement of the CSR-format's basic ideas for sparse banded matrices derived
    from structured grids. Naturally, the CSR-format has been chosen as a landing pad for the creation of matrix objects
    in C3SR-format. Eigen \cite{eigen:website} is a general purpose C++ template library for linear algebra. Its sparse
    matrices can be stored in a CSR-format variant from which all C3SR-matrices used for this project are generated.

    The CSR-format does not specify any order in which a row's nonzeros' information ought to appear in data. In order
    to easily recognize two rows with equal values or equal structure the rows' segments within the value and the
    column-index arrays are sorted in ascending fashion with respect to the rows' common column indices. This task can
    be fully parallelized across multiple threads and greatly improves the performance of the construction of C3SR
    objects. Once a definite order among a row's nonzeros has been established the nonzeros' values and column indices
    are compressed separately to create the matrix's representation in C3SR-format.

    Firstly, the C3SR-format's value array V and its index-pointer array VS are populated by removing duplicate segments
    from the CSR-format's value array which pertain to different rows. For the description of the algorithm it is
    condusive to conceive of the nonzero values corresponding to a matrix row as a word made from individual letters.
    The task may then be expressed in a simple manner: Given an array of letters comprising an unknown number of
    different words of possibly different lengths, whose first letters are pointed by the elements of a separate
    index-pointer array, remove duplicate words and adjust the index-pointers accordingly. The order in which the words
    appear in the compressed output array shall adhere to the original order in which they show up in the input array.
    This increases the likelyhood that data which relates to contiguous matrix rows which cannot be compressed appears
    contiguously in the arrays which is condusive to spatial data locality for matrix-vector multiplication.

    The compression is achieved in four steps which are outlined in Figure \ref{fig:c3sr-compression-scheme}: First, the
    data is sorted lexicographically by words (I $\rightarrow$ II) after which duplicate words and their index-pointers
    are discarded (II $\rightarrow$ III). Then, using the unique words, the original order of these words is restored by
    sorting by the words' original indices. Utilizing the lengths of the words a sorted look-up table of their starting
    positions is created (III $\rightarrow$ IV). Finally, in order to build the new index-array the original input data
    is traversed once again and the individual words' starting indices relative to the new, compressed word array are
    quickly retrieved from the look-up table through binary searches (IV $\rightarrow$ V). Take note that the
    lexicographical ordering is well-defined for words whose "letters" are numerical values, as is the case for the
    values and column-indices of a matrix in CSR-format.

    \begin{figure}[H]
      \centering
      \captionsetup{width=0.9\columnwidth}
      \input{./assets/c3sr-compression-scheme.tex}
      \toccaption{Schematic diagram of the C3SR compression scheme.}{Starting out at a dense array of letters segmented
        into distinct words by a secondary index-pointer array (I), the data structure is sorted lexicographically by
        the words and, among identical words, by the words' indices (II). Duplicate words and their index-pointers are
        removed (III) and the remaining data structure is sorted by the indices which restores the original order in
        which the words appeared retaining only unique words. Knowing the words' lengths a sorted look-up table for the
        index-pointers is set up (IV). Finally, the new index-pointer array is built by traversing the original data
        structure's words and retrieving the corresponding new index from the look-up table (V). The diagram shows the
        first $5$ words, $3$ of which are unique (A, B, C) indicated by different field widths. The lexicographical
        order of all words is B < A < C < $\ldots$. Index-pointers always point the first letter in a word and their
        values are indicated by arrows to the words they point. The drawn arrows end in the central area of the word
        they point for the sake of recognizability.}
      \label{fig:c3sr-compression-scheme}
    \end{figure}

    In order to compress the CSR-matrix's structural information first the peg indices JP are retrieved, i.e. the
    column-indices of each row's first nonzero element. As the CSR-matrix's nonzeros have been previously sorted the peg
    index of a row is necessarily the very first entry in the row's segment within the column-index array.

    Using the previously acquired peg indices every element in a row's segment within the CSR-matrix's column-index
    array is reduced by the corresponding row's peg index. This uncompressed array of column-index patterns is then
    subjected to the same compression scheme described above for the value array. This populates the C3SR-format's J and
    JS arrays. Finally, the row-size array RS is populated by computing the adjacent difference across the CSR-format's
    row-pointer array, an operation which constitutes the exclusive scan's inverse operation used to construct the
    row-pointer array for a CSR-matrix from the number of nonzeros in each row.

  \section{Run-Length-Increment Encoding}

    Building upon the construction scheme and its compression method the storage sizes of matrices in C3SR-format can be
    further reduced by run-length encoding a subset of the C3SR-format's data arrays. The index-pointer arrays VS and
    JS, the peg-index array JP and the row-size array RS each contain one entry per matrix row after the object has been
    constructed in the above manner. When dealing with sparse banded matrices derived from structured grids these arrays
    exhibit a distinct composition suitable for a variant of run-length encoding.

    Using the nomenclature introduced in Section \ref{sec:vectorized-simd-multiplication-scheme}, matrix slices of
    diagonal structure produce segments within JP where each value increases by $1$ with respect to its predecessor or,
    for uniform structure, each value is constant. The values within the corresponding segment of JS are constant,
    pointing the same pattern for both types of structural composition. Collated values produce a segment of identical
    entries in VS while for arbitrary values the segment's entries increase by the constant number of nonzeros in each
    row. Finally, any matrix slice with composition which is not fully arbitrary yields a segment in RS whose values are
    constant, corresponding to the number of nonzeros in each row.

    Thus for the type of matrices relevant to this thesis the arrays mentioned above consist chiefly of segments whose
    elements either increase by a fixed stride $n$ or are constant. As constant segments are equivalent to an increment
    of $0$ an extension of the common run-length encoding scheme becomes applicable to the above configurations. As opposed to
    only compressing runs of constant values the idea is to compress runs of a fixed but arbitrary increment. This
    compression scheme shall be referred to as \keyword{run-length-increment encoding} and is layed out in Figure
    \ref{fig:rli-encoding}.

    \begin{figure}[ht]
      \centering
      \captionsetup{width=0.9\columnwidth}
      \input{./assets/rli-encoding.tex}
      \toccaption{Run-length-increment encoding scheme.}{Segments of a dense array whose elements are incremented by a
        fixed offset with respect to their respective predecessors are encoded into a single triplet consisting of the
        segment's first element's positional index, the first element's value and the offset between elements. The index
        allows to quickly retrieve values from the compressed data structure through binary searches. The image shows
        two such segments, referred to as `runs', and their corresponding triplets. For ease of legibility the elements'
        symbol and the positional indices have been substituted between runs ($y_{m +i} = x_{n+r+i} \,\, i \in \{0, 1,
        \ldots \}$).}
      \label{fig:rli-encoding}
    \end{figure}

    A run of elements with a constant increment is encoded as a triplet of the run's first element's value $x_n$, its
    positional index $n$ in the underlying uncompressed array and the increment between adjacent values $\Delta_x$
    referred to as the triplet's delta. A final triplet whose index is equal to the number of elements in the array
    designates the end of the data structure.

    In contrast to what the name 'run-length-increment encoding' might suggest, instead of saving the length of a run
    its first entry's index is stored. This causes the triplet indices to be sorted in ascending fashion which allows to
    implement a transparent pseudo-random access into the data structure. To access an element at a specific index $i$
    in the original, uncompressed array a simple binary search over the triplet indices is required to retrieve the
    corresponding triplet $(j, x_j, \Delta)$ and adding the triplet's delta $\Delta$ times the index's remainder $(i-j)$
    to the triplet's initial value $x_j$ will produce the result. Figure \ref{fig:rli-encoding-example} shows a
    complete example of a run-length-encoded numeric array.

    \begin{figure}[ht]
      \centering
      \captionsetup{width=0.9\columnwidth}
      \input{./assets/rli-encoding-example.tex}
      \toccaption{Run-length-increment encoding example.}{Numeric array (top) comprising three RLI-runs plus a
        past-the-end triplet (bottom). Elements belonging to a common RLI-triplet are highlighted by color. Array
        indices are assumed to start at $0$.}
      \label{fig:rli-encoding-example}
    \end{figure}

    Due to the fact that the RLI-triplets' indices are used as pivots for binary searches the data structure is
    implemented as a structure of arrays, segregating the indices into a dedicated array which lays them them out in a
    contiguous section of memory. This improves spatial locality and thus increases performance through better cache
    usage. For the sake of conciseness run-length-increment encoding will nevertheless be referred to in terms of
    triplets including the subsequent paragraph about iterators.

    Note that even though a pseudo random access into a RLI-data structure is of logarithmic complexity and can thus be
    performed fairly quickly, realizing every access via the aforementioned binary search would not be viable for any
    implementation of matrix-vector arithmetic. However, owed to the fact that matrix-vector multiplication, if
    performed row-by-row as done herein, requires only adjacent accesses for all arrays which are subjected to
    run-length-increment encoding this is unnecessary. As every entry of the original, uncompressed array corresponds
    to a row in the matrix the arithmetic for a subsequent matrix row requires accessing the subsequent element. This
    can be implemented very economically using an iterator abstraction.

    The iterator maintains the value of the current index it refers to with respect to the original, uncompressed array
    and a pointer to the triplet to which span said index belongs to. Iterators are constructed and dereferenced by the
    method explained above used for pseudo random access based on a binary search. Incrementing the iterator, i.e.
    making it `point' the subsequent element, is done by simply incrementing the index variable and, if the incremented
    index is equal to or greater than the next triplet's starting index, adjusting the pointer to point that next
    triplet. Using C++ lingo, this constitutes the implementation of a forward iterator.

  \section{Vectorization of Matrix-Vector Multiplication} \label{sec:vectorization-of-mvm}

    In Section \ref{sec:vectorized-simd-multiplication-scheme} the distinct SIMD schemes for the vectorized
    matrix-vector multiplication schemes and their method of detection via accesses into the index-pointer arrays JS
    and VS and the peg-index array JP have been introduced. The question of when this slice analysis should be
    performed and in what manner the matrix should be partitioned into said slices remains to be answered.

    A downside to the sparse matrix compression and data encoding schemes is that the final C3SR-matrix object is very
    inflexible with regards to changes to its structure or its values. If the underlying mathematical matrix needs to
    be changed a new C3SR-matrix will likely have to be created. Thus, for the prototyping of the project the matrix
    objects are assumed to be static after being created and to not undergo any changes to their data. Naturally, the
    choice is made to perform the analysis of the matrix's slices' compositions at construction time after the data
    structures have been populated. 

    The matrix's partitioning into slices of rows of common composition can either be performed in an exhaustive
    manner, whereby each slice is chosen to span as many rows as possible or, alternatively, using a fixed size for
    all slices or a mixture of both concepts. The exhaustive approach deals precisely with slice borders where the
    type of composition changes, but entails a dynamic overhead when slices are either too small or too large for
    vector registers to process in a single run. Conversely, partitioning the matrix into slices whose widths
    correspond to the hardware's vector register width has many benefits. The mapping between the arithmetic schemes
    developed in Section \ref{sec:vectorized-simd-multiplication-scheme} and instructions on vector registers becomes
    obvious and its implementation straightforward, exposing more information at compile time than would be available
    if an exhaustive, dynamic partitioning were chosen. Thus the former, static approach is taken.

    After the matrix's data structures have been initialized the matrix is traversed in groups of $8$ contiguous rows,
    beginning at the first row, and each group's slice composition is determined via the aforementioned methods. The
    fixed slice width has been chosen to match the number of double precision floating point numbers that fit into a
    AVX512 vector register. The analysis results are stored in a dedicated data array which is consulted when
    performing vectorized matrix-vector multiplication. The data array will be referred to as COMP, the slice
    composition array.

    Functionality concerned with vectorization is implemented using UMESimd \cite{umesimd2017}, a C++ template library
    which provides type-based abstractions to express vectorized operations using a simple, mathematical notation. The
    operations are implemented via vendor-specific compiler intrinsics which provide access to specific instructions
    without the need to write assembly code. Implementations for all operations relevant to this project are available
    from the library, namely the load and store operations, fused-multiply-add and gather. Aside from the simple
    interface UMESimd provides the additional benefit that the source code can be deployed to systems which lack SIMD
    hardware or whose vector registers are less wide than originally anticipated by the programmer. Compile-time flags
    set by the compiler are queried by UMESimd to reveal which instruction set the target architecture supports and
    fallback implementations are available which may split up operations into multiple instructions on smaller vector
    registers or even use a fully scalar, sequential substitute.

    In conclusion, vectorized matrix-vector multiplication is performed by traversing the slice composition array
    COMP, whose values represent the arithmetic scheme to be applied to the corresponding group of $8$ rows which are
    then processed after which the next group of $8$ rows are served.

    % \Todo{Architekturen mit schneller Stride-Gather Instruktion suchen}

  %\Todo{Bei SIMD Scheme II}

  %   Thus, in contrast to the previous multiplication scheme no gather instruction is required to compute a
  %   matrix-vector product which significantly reduces the operation's comprexity resulting in faster execution times.

  \section{Parallelization of Matrix-Vector Multiplication}

    As opposed to the CSR-format spreading the arithmetic workload of matrix-vector multiplications for the C3SR-format
    evenly among CPU cores and hardware threads is less trivial. The CSR-format's row-pointer array contains the scan of
    the number of non-zeros up to a row's respective index and as the number of non-zeros in a row is roughly
    proportional to its arithmetic workload ($n_\text{nnz}$ multiplications and $(n_\text{nnz} - 1)$ additions per
    $n_\text{nnz}$ non-zeros) spreading the workload evenly among $n_T$ theads is trivial requiring the row-pointer
    array to be partitioned such that the partitions' values span evenly sized ranges of indices. As the row-pointer
    array is sorted in ascending fashion this can be achieved very efficiently by $(n_T - 1)$ binary searches.

    Even more importantly than being able to reliably estimate the arithmetic workload is the fact, that the CSR format
    allows to assess the amount of data movement required for the matrix-vector multiplication of a matrix slice from
    the row-pointer array with equal precision. Per nonzero in the matrix one column-index and one numeric value have to
    be loaded in addition to the access to the argument vector's entry while one numeric value has to be written to memory
    per matrix row. This allows to apply the above simple load balancing scheme regardless of the size of the matrix or
    its distribution of nonzeros across its rows.

    While the arithmetic workload of a matrix-vector multiplication for a matrix in CSR-format is comparable to the
    C3SR-format's equivalent scalar scheme as displayed in Figure \ref{fig:csr-vs-c3sr-mvm-scalar}, the latter's memory
    footprint cannot be assessed in the same general manner. By virtue of the C3SR-format's compression scheme the
    number of rows and nonzeros in a matrix slice does not provide conclusive information about the data movement
    necessary for its arithmetic. While a range of rows may exhibit a structured layout of its nonzeros resulting in
    minute storage size requirements, as exemplified in the measurements of storage density in Section
    \ref{sec:rel-object-size-fully-structured}, another equally wide range of rows with the same number of nonzeros may
    be less structured and uncompressible which would entail a storage size orders of magnitudes higher. Thus, a general
    implementation of parallelized arithmetic for the C3SR-format must either use dynamic load balancing and
    work-stealing techniques or, alternatively, must include a preliminary analysis of its data in order to determine a
    mapping of ranges of rows with approximately equal amounts of memory movements. The latter approach has been deemed
    too inflexible because, due to the possibly convoluted compression, it cannot be ascertained a priori for all
    configurations whether a matrix-vector multiplication is, in fact, a memory-bound operation. One would might force
    to optimize a problem for balanced memory movement where the CPU arithmetic had become the actual bottleneck.

    An additional issue to consider arises for large, multi-socket shared-memory systems such as those being used for
    benchmarking this project. On such architectures the proximity of the main memory accessed by a CPU has to be taken
    into account in order to avoid severe bandwidth penalties. CPUs and memory are organized into NUMA nodes within
    which communication is significantly faster than accessing data from a different node. Thus non-uniformity of memory
    accesses has to be respected when parallelizing the data and the workload of a matrix-vector multiplication. This
    means, that the data arrays have to be distributed across the NUMA regions during construction of the matrix object
    in such a way that memory accessed by a CPU falls in its corresponding NUMA-region as much as possible. This
    would require a priori knowledge of the final data layout even before the compression has been performed which is
    impossible for the general case. As an alternative the object could be constructed and a copy of its data arrays be
    spread correctly across the NUMA regions.

    For this project a simpler, more pragmatic method was chosen to account for NUMA locality. Each of the C3SR-format's
    data arrays is spread evenly across all available NUMA-regions by parallel fill operation on all cores. The
    allocation size is assumes to be the absolute worst case that arises if no compression takes place at all in which
    case the C3SR-format would essentially produce an expensive copy of the underlying CSR-matrix's object. Afterwards
    the matrix is constructed as usual and data is written into the arrays.

    Motivated by test matrices
    used to characterize and benchmark the C3SR-format's implementation, which are detailed in Section, the
    C3SR-format's data arrays are all spread proportionally
    \ref{sec:test-matrices},

    Note that implementing a strictly NUMA-local matrix-vector-multiplication


    Implementing proper NUMA-locality requires 


    ... NUMA alliokation aber resize: Kein Problem, weil bei kleinen Objekten sowieso X, Y größer sind

    work Cores and memory are organized into NUMA-nodes

    ... Problem mit work-stealing tritt beiz  

    dynamic scheduling  = dynamic( !) = overhead

    Workstealing eingestellt, weil verwirrend mit Numa; Performance für kleinere Matrixgrößen schlechter; Wir
    interessieren uns aber nur für große Objekte jenseits von Cache-größenordnungen

    method to determine the final array .. allocated 

    the fact that the actual arithmetic required to evaluate a matrix-vector product for a
    slice of matrix rows can be estimated reliably from the corresponding row-pointer array,

    % \Todo{Mvm schemata können seriell oder thread-parallel ausgeführt werden. ... }

    % Ansatz: Nach index-raum der Rows parallelisieren, oder nach Row-size. == Heuristic, as true arithmetic workload
    % cannot be known.
